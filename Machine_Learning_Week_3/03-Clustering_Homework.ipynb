{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering-Homework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IbCj4qqPdBR",
        "colab_type": "text"
      },
      "source": [
        "## K-means clustering\n",
        "In this homework your task will be to try the k-means clustering algorithm on a different dataset with various settings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCCUDPUaZWBr",
        "colab_type": "text"
      },
      "source": [
        "Let's use the wine dataset, which has 13 features and 3 sorts (classes) of wine (unnamed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvfeMtJFZnjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import ...\n",
        "wine = datasets.load_wine()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62PxNHzpZp_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the dataset into the pandas DataFrame\n",
        "X = ...\n",
        "y = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoSfIAeiZw1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's try some scatter plots first to see if any feature combination gives seems promising for a clustering algorithm.\n",
        "plt.subplot(...) # Make more than one subplot\n",
        "plt.scatter(...)\n",
        "plt.title(...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktKh-NaXbJT5",
        "colab_type": "text"
      },
      "source": [
        "A clustering algorithm (here: k-means) can, of course, work with more than two features, however, for the sake of nice visualizations, let's use two features at a time. Later, we can include more features and see if our performance measures suggest any improvement. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTGPqAs0bsAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pick some two features that seem to give nice separated clusters in the plots above:\n",
        "features_2 = ['feature0','feature1'] # replace with your feature names\n",
        "X_2 = X[features_2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lz49vPUcOJ-",
        "colab_type": "text"
      },
      "source": [
        "**Note:** do not forget to scale your features!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXCWG_Daclfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now apply k-means to your data. Determine the best k value using WCSS method:\n",
        "...\n",
        "# Repeat this for 3 different pairs of features, see which one works best.\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDsVGUrFc7Dp",
        "colab_type": "text"
      },
      "source": [
        "### Clustering evaluation:\n",
        "\n",
        "Evaluation of the result of a clustering algorithm is a more difficult task than for classification, because in the general case the ground truth (the correct answers/labels) is not available; in fact, there is often no target variable. Additionally, evaluating an algorithm using the same distance measure as the one it was produced with can be biased. \n",
        "\n",
        "There are, however, nevertheless, multuiple evaluation measures, both for the case where the ground truth data is present and when it is absent. In this homework, let's consider a few of these measures: Adjusted Rand index, Homogeneity, completeness and V-measure; and Silhouette Coefficient. Both of them are implemented in the *sklearn* library.\n",
        "\n",
        "**Adjusted Rand index** requires ground truth labels and compares them to the labels produced by the clustering algorithm (the way they are named/numbered does not matter). The result is a number in the range [-1, 1].\n",
        "\n",
        "**Homogeneity, completeness and V-measure** also require ground truth labels. These measures are very similar to per-cluster precision, recall and F1-score:\n",
        "**Homogeneity** score is at its maximum if each cluster contains only members of a single class. In turn, **completeness** attains its maximum when all members of a given class are assigned to the same cluster.\n",
        "\n",
        "For mathematical formula, reference, code and more evaluation metrics, see:  **[Clustering performance evaluation](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation)**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns4XMYOkj1CR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For each of the instances of the clustering algorithm implemented earlier, complute the evaluation measures, as defined above. You can use the code provided in the link above.\n",
        "# You can also use these measures to see how the k-means algorithm performs when given all 13 features.\n",
        "# The output can be a table, with rows being algorithm evaluation instances (different features, different k) and columns being evaluation metrics."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emCKr-wqoDfG",
        "colab_type": "text"
      },
      "source": [
        "## Optional: Hierarchical clustering\n",
        "Let's explore another type of clustering algorithms in more detail using the wine dataset (3 classes). Hierarchical clustering algorithms (HCA) (https://en.wikipedia.org/wiki/K-means_clustering) also produces clusters, however, it does so also producing a dendrogram (tree structure) of the clusters, thus the name of the technique. \n",
        "\n",
        "There are two main approaches: \n",
        "1. Top-down (divisive): start with everything in one cluster and split it;\n",
        "2. Bottom-up (agglomerative): start with each instance being its own cluster and then merge them.\n",
        "\n",
        "The image below shows the algorithm (agglomerative clustering) and an example output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zk7Csn0n_lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import pandas as pd\n",
        "from sklearn import datasets, cluster\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k0R_gqJrqTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's use wine again\n",
        "wine = datasets.load_wine()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZX8sOuOr3g9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert it to pandas dataframe if necessary\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.DataFrame(data.target, columns=['Target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjeervhNKlPe",
        "colab_type": "text"
      },
      "source": [
        "Like k-means clustering, hierarchical clustering also requires a **distance measure** (the parameter is called 'affinity'). Euclidean distance metric is used as a default.\n",
        "\n",
        "Apart from the distance metric, the algorithm also needs a **linkage criterion**. The linkage criterion determines **from where** the distance is computed, in other words, how is the distance between the two clusters is defined. The distance (e.g. euclidean) between two clusters can be measured as the distance between their closest elements (single linkage), their farthest elements (complete linkage), their centers (average linkage). A reasonable default choice is the Ward's method.\n",
        "\n",
        "The choice of both metric and linkage can be determined from the domain knowledge (not always possible) or by validation (if clustering eventually used for classification).\n",
        "\n",
        "In practice, hierarchical clustering is used less often than k-means."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZi3xiRh5pqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's apply clustering to several different pairs of features first\n",
        "two_features = ['feature 1','feature 2'] # replace with appropriate features\n",
        "# two_features = ['alcohol', 'malic_acid']\n",
        "average_agglomerative_clustering = cluster.AgglomerativeClustering(\n",
        "        n_clusters=3, linkage='average', affinity='euclidean')\n",
        "predicted = average_agglomerative_clustering.fit(X.iloc[0:20,:]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlqTj6nzACeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the clusters (colored as prediction results) as a scatterplot, as well as the actual labels\n",
        "# Disclaimer: this is just for testing purposes\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfYMxKAoYQum",
        "colab_type": "text"
      },
      "source": [
        "Let's also print the actual dendrogram produced by the algorithm (more easily seen with a few instances):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WunJMRM2W_Il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.cluster.hierarchy import dendrogram\n",
        "\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "\n",
        "    # Children of hierarchical clustering\n",
        "    children = model.children_\n",
        "\n",
        "    # Distances between each pair of children\n",
        "    # Since we don't have this information, we can use a uniform one for plotting\n",
        "    distance = np.arange(children.shape[0])\n",
        "\n",
        "    # The number of observations contained in each cluster level\n",
        "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
        "\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSKNVlsoXLF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "56820e81-9d1a-43bd-f482-8391bf0bf607"
      },
      "source": [
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plot_dendrogram(predicted, labels=predicted.labels_)\n",
        "plt.show()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAELCAYAAADX3k30AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnBO9mVnBOdGbmRWcE72ZWcH9f7vbfTmYZ6hwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}